# -*- coding: utf-8 -*-
"""tvs_bikedekhoscrap.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dXtwP-eu22AwZi2p80iwyldFWW6jGGOK
"""

import pandas as pd
import re
import requests
from bs4 import BeautifulSoup
from selenium import webdriver
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.common.by import By
import time
from geopy.exc import GeocoderTimedOut
from geopy.geocoders import Nominatim
import numpy as np

# url ='https://www.bikedekho.com/new-bikes#all_brands'
# driver = webdriver.Firefox()
# driver.get(url)

# tvs = driver.find_element(By.CLASS_NAME, "BrIconNewCar")
# tvs.click()

url ='https://www.bikedekho.com/tvs-bikes'
headers={'User-Agent':'Mozilla/5.0 (Windows NT 6.3; Win 64 ; x64) Apple WeKit /537.36(KHTML , like Gecko) Chrome/80.0.3987.162 Safari/537.36'}
r=requests.get(url,headers=headers).text
driver = webdriver.Firefox()
driver.get(url)

len(r)

soup = BeautifulSoup(r,'lxml')

len_link = len(soup.find_all('div',class_ = 'gsc_col-sm-12 gsc_col-xs-12 gsc_col-md-8 listView holder posS'))
len_link

A= soup.find_all('h3')[:17]
A

bike_name = []
price = []
mileage= []
for i in range(len_link):
    try:
        bike_name.append(soup.find_all('h3')[i].text)
    except:
        bike_name.append('Na')
    try:
        price.append(soup.find_all('div', class_ = 'price')[i].text)
    except:
        price.append('Na')
    try:
        if 'kmpl' in soup.find_all('div', class_ = 'dotlist')[i].text:
            m=soup.find_all('div', class_ = 'dotlist')[i].text
            mileage.append(m.split(' ')[0])
            
        else:
            mileage.append('Na')
    except:
        mileage.append('Na')

col=['bike_name', 'price', 'mileage'] 
df=pd.DataFrame({'bike_name': bike_name, 'price': price, 'mileage': mileage})
df

links = []
for i in range(len_link):
    for j in A[i].find_all('a', href = True):
        links.append('https://www.bikedekho.com' + j['href'])
len(links)

engine = []
power = []
torque= []
for i in links:
    headers={'User-Agent':'Mozilla/5.0 (Windows NT 6.3; Win 64 ; x64) Apple WeKit /537.36(KHTML , like Gecko) Chrome/80.0.3987.162 Safari/537.36'}
    r=requests.get(i,headers=headers).text
    soup = BeautifulSoup(r,'lxml')
    try:
        for i in soup.find_all('td', class_ = 'gsc_col-xs-12 textHold')[0]:
            engine.append(i.text)
    except:
        engine.append('Na')

    try:
        for i in soup.find_all('td', class_ = 'gsc_col-xs-12 textHold')[1]:
            power.append(i.text)
    except:
        power.append('Na')

    try:
        for i in soup.find_all('td', class_ = 'gsc_col-xs-12 textHold')[2]:
            torque.append(i.text)
    except:
        torque.append('Na')

col = ['bike_name','price','mileage','Engine','power','Torque'] 
df= pd.DataFrame({'bike_name':bike_name, 'price':price, 'mileage':mileage, 'engine':engine, 'power':power, 'torque':torque})
df

df['bike_name']= df['bike_name'].str.replace('TVS', 'TVS:')

df[['min_price', 'max_price']]= df['price'].str.split('-', expand = True)

df[['Brand', 'Bike_name']] = df['bike_name'].str.split('::', expand = True)

df.drop(columns = ['price', 'bike_name'], inplace= True)

df=df.iloc[:,[6,7,4,5,0,1,2,3]]
df

